name: AI Verification & Site Update

on:
  schedule:
    - cron: '0 */6 * * *' # Ogni 6 ore
  workflow_dispatch:      # Manuale

permissions:
  contents: write

jobs:
  ai-and-sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Scarica tutta la storia per evitare conflitti

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install pandas requests numpy gspread google-auth tavily-python openai

      # --- STEP 1: AGENTE AI ---
      - name: ü§ñ Run AI Agent
        env:
          TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GCP_CREDENTIALS_JSON: ${{ secrets.GCP_CREDENTIALS_JSON }}
        run: python3 scripts/ai_agent.py || echo "AI Agent finished with warnings (continuing...)"

      # --- STEP 2: GENERAZIONE DATI & CLASSIFICAZIONE ATTORI ---
      - name: üè≠ Process Data & Classify Actors
        run: |
          python3 <<'EOF'
          import pandas as pd
          import json
          import sys
          import numpy as np
          import requests
          import io
          import re
          import math

          # CONFIGURAZIONE
          SHEET_URL = "https://docs.google.com/spreadsheets/d/1NEyNXzCSprGOw6gCmVVbtwvFmz8160Oag-WqG93ouoQ/export?format=csv"
          
          print("üîÑ Scaricamento Database Completo...")
          try:
              response = requests.get(SHEET_URL)
              response.raise_for_status()
              df = pd.read_csv(io.StringIO(response.text))
          except Exception as e:
              print(f"‚ùå CRITICAL ERROR: {e}")
              sys.exit(1)

          # NORMALIZZAZIONE COLONNE
          df.columns = df.columns.str.strip().str.lower()
          
          # --- FIX GLOBALE NAN -> NULL ---
          # Questa riga √® la "Sterilizzazione": converte tutti i NaN di Pandas in None (Python)
          # Quando salviamo il JSON, i None diventeranno automaticamente 'null', che √® valido.
          df = df.replace({np.nan: None})
          
          def get_col(candidates):
              for c in candidates:
                  if c in df.columns: return c
              return None

          col_lat = get_col(['latitude', 'lat'])
          col_lon = get_col(['longitude', 'lon', 'long'])
          col_desc = get_col(['description', 'descrizione', 'notes', 'note'])
          col_loc = get_col(['location', 'luogo', 'city'])
          col_date = get_col(['date', 'data'])
          col_type = get_col(['type', 'tipo', 'type of attack'])
          col_title = get_col(['title', 'titolo'])
          col_link = get_col(['source', 'link', 'fonte'])
          col_video = get_col(['video', 'video_url'])
          col_ver = get_col(['verification', 'verifica'])
          col_int = get_col(['intensity', 'intensit√†'])
          
          if not col_lat or not col_lon:
              print("‚ùå Errore: Colonne coordinate non trovate.")
              sys.exit(1)

          # CLASSIFICAZIONE ATTORI
          def classify_actor(row):
              # Gestiamo il caso None convertendolo in stringa vuota per l'analisi
              desc_val = row.get(col_desc) or ""
              title_val = row.get(col_title) or ""
              loc_val = row.get(col_loc) or ""
              
              text = (str(desc_val) + " " + str(title_val)).lower()
              loc = str(loc_val).lower()
              
              if re.search(r'russian (force|army|missile|drone|shelling)|forces of rf|shahed|iskander|kalibr| FAB-\d+|kh-\d+', text):
                  return 'RUS'
              if re.search(r'ukrainian (force|army|missile|drone)|zsu|uaf|himars|atacms|storm shadow|magura', text):
                  return 'UKR'
              if re.search(r'belgorod|kursk|voronezh|rostov|crimea|sevastopol|kerch|moscow|krasnodar|bryansk', loc):
                  return 'UKR'
              if re.search(r'kyiv|kiev|kharkiv|kharkov|odesa|odessa|lviv|dnipro|zaporizhzhia|vinnytsia|sumy|poltava', loc):
                  return 'RUS'
              return 'UNK'

          # GENERAZIONE GEOJSON
          features = []
          stats = {'RUS': 0, 'UKR': 0, 'UNK': 0}

          for _, row in df.iterrows():
              try:
                  # Se lat/lon sono None (ex NaN), saltiamo la riga
                  if row[col_lat] is None or row[col_lon] is None: continue
                  lat = float(row[col_lat])
                  lon = float(row[col_lon])
              except: continue

              actor_code = classify_actor(row)
              stats[actor_code] += 1

              # Pulizia campi testo (None diventa "")
              desc = str(row.get(col_desc) or "")
              loc = str(row.get(col_loc) or "")
              
              # Calcolo Intensit√† Sicuro
              # Se √® None o stringa vuota, mettiamo default
              try:
                  raw_int = row.get(col_int)
                  if raw_int is None or raw_int == "":
                      intensity = 0.2
                  else:
                      intensity = float(raw_int)
                      # Extra check matematico, anche se il replace globale dovrebbe aver risolto
                      if math.isnan(intensity): intensity = 0.2
              except: intensity = 0.2

              props = {
                  "title": str(row.get(col_title) or "Evento"),
                  "date": str(row.get(col_date) or ""),
                  "type": str(row.get(col_type) or "General"),
                  "location": loc,
                  "link": str(row.get(col_link) or ""),
                  "verification": str(row.get(col_ver) or "not verified"),
                  "description": desc,
                  "video": str(row.get(col_video) or ""),
                  "intensity": intensity,
                  "actor_code": actor_code
              }
              features.append({
                  "type": "Feature",
                  "geometry": {"type": "Point", "coordinates": [lon, lat]},
                  "properties": props
              })

          with open("assets/data/events.geojson", "w", encoding="utf-8") as f:
              json.dump({"type": "FeatureCollection", "features": features}, f, ensure_ascii=False, indent=2)
          print(f"‚úÖ events.geojson: Generati {len(features)} eventi. Stats: {stats}")

          # GENERAZIONE TIMELINE
          tl_events = []
          for feat in features:
              p = feat['properties']
              try:
                  d_str = p['date']
                  year, month, day = "2024", "01", "01"
                  if '-' in d_str: year, month, day = d_str.split('-')[:3]
                  elif '/' in d_str: day, month, year = d_str.split('/')[:3]
                  if len(year) == 2: year = "20" + year

                  html = f"<b>Tipo:</b> {p['type']}<br><b>Attore:</b> {p['actor_code']}<br><b>Luogo:</b> {p['location']}<br><br>{p['description']}"
                  tl_obj = {
                      "start_date": {"year": int(year), "month": int(month), "day": int(day)},
                      "text": { "headline": p['title'], "text": html },
                      "group": p['type']
                  }
                  if p['video']: tl_obj['media'] = { "url": p['video'], "caption": "Fonte Video" }
                  tl_events.append(tl_obj)
              except: continue

          with open("assets/data/events_timeline.json", "w", encoding="utf-8") as f:
              json.dump({"title":{"text":{"headline":"Timeline"}}, "events":tl_events}, f, ensure_ascii=False)
          print(f"‚úÖ events_timeline.json: Generati {len(tl_events)} slide.")
          EOF

      # --- STEP 3: FORCE COMMIT (SOLUZIONE AL CONFLITTO) ---
      - name: Commit and push updates
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          
          git fetch origin main
          git reset --soft origin/main
          git add assets/data/events.geojson assets/data/events_timeline.json
          
          if git diff --cached --quiet; then
            echo "Nessuna modifica ai dati."
            exit 0
          fi
          
          git commit -m "Auto-update: Data Clean & Actor Fix"
          git push origin main
